{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f7f102d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-26T18:33:42.900338Z",
     "iopub.status.busy": "2025-04-26T18:33:42.900117Z",
     "iopub.status.idle": "2025-04-26T18:33:44.997988Z",
     "shell.execute_reply": "2025-04-26T18:33:44.997267Z"
    },
    "papermill": {
     "duration": 2.101806,
     "end_time": "2025-04-26T18:33:44.999509",
     "exception": false,
     "start_time": "2025-04-26T18:33:42.897703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_40.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_23.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_18.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_21.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_38.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_37.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_36.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_14.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_6.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_35.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_34.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_32.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/token_info_onchain_divers.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_17.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/test_unlabeled.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_8.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_7.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_24.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_41.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_9.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_33.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_26.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_11.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_39.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_10.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_31.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_16.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/dune_token_info_v2.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_4.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_28.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_25.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_22.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_2.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_30.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_19.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_12.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/dune_token_info.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/train.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_29.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_15.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/token_info_onchain_divers_v2.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_1.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_20.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_13.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_27.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_5.csv\n",
      "/kaggle/input/pump-fun-graduation-february-2025/chunk_3.csv\n",
      "/kaggle/input/pump-fun-api-solana-tokens-info/pump_fun_api_info.parquet\n",
      "/kaggle/input/solana-skill-sprint-memcoin-graduation/sample_submission.csv\n",
      "/kaggle/input/solana-skill-sprint-memcoin-graduation/test_unlabeled.csv\n",
      "/kaggle/input/solana-skill-sprint-memcoin-graduation/train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "203829ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T18:33:45.003961Z",
     "iopub.status.busy": "2025-04-26T18:33:45.003635Z",
     "iopub.status.idle": "2025-04-26T18:35:50.571244Z",
     "shell.execute_reply": "2025-04-26T18:35:50.570327Z"
    },
    "papermill": {
     "duration": 125.571289,
     "end_time": "2025-04-26T18:35:50.572597",
     "exception": false,
     "start_time": "2025-04-26T18:33:45.001308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5932, number of negative: 505713\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 511645, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.011594 -> initscore=-4.445608\n",
      "[LightGBM] [Info] Start training from score -4.445608\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0427593\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's binary_logloss: 0.0427383\n",
      "submission.csv saved!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "BASE_API  = \"/kaggle/input/pump-fun-api-solana-tokens-info\"\n",
    "BASE_GRAD = \"/kaggle/input/pump-fun-graduation-february-2025\"\n",
    "BASE_COMP = \"/kaggle/input/solana-skill-sprint-memcoin-graduation\"\n",
    "\n",
    "INFO1_FILE = os.path.join(BASE_API, \"pump_fun_api_info.parquet\")\n",
    "TRAIN_FILE = os.path.join(BASE_COMP, \"train.csv\")\n",
    "TEST_FILE  = os.path.join(BASE_COMP, \"test_unlabeled.csv\")\n",
    "SAMPLE_SUB = os.path.join(BASE_COMP, \"sample_submission.csv\")\n",
    "\n",
    "\n",
    "info1 = pl.read_parquet(INFO1_FILE, columns=[\"mint\", \"created_timestamp\"])\n",
    "\n",
    "\n",
    "agg_df = None\n",
    "for path in glob.glob(os.path.join(BASE_GRAD, \"chunk_*.csv\")):\n",
    "    for chunk in pd.read_csv(\n",
    "        path,\n",
    "        usecols=[\"base_coin\", \"base_coin_amount\", \"quote_coin_amount\", \"fee\"],\n",
    "        chunksize=500_000\n",
    "    ):\n",
    "        chunk.rename(columns={\"base_coin\": \"mint\"}, inplace=True)\n",
    "        grp = chunk.groupby(\"mint\").agg(\n",
    "            tx_count=(\"mint\", \"size\"),\n",
    "            sum_base=(\"base_coin_amount\", \"sum\"),\n",
    "            sum_quote=(\"quote_coin_amount\", \"sum\"),\n",
    "            sum_fee=(\"fee\", \"sum\"),\n",
    "        )\n",
    "        agg_df = grp if agg_df is None else agg_df.add(grp, fill_value=0)\n",
    "\n",
    "agg_df[\"mean_base\"]  = agg_df[\"sum_base\"]  / agg_df[\"tx_count\"]\n",
    "agg_df[\"mean_quote\"] = agg_df[\"sum_quote\"] / agg_df[\"tx_count\"]\n",
    "agg_df[\"mean_fee\"]   = agg_df[\"sum_fee\"]   / agg_df[\"tx_count\"]\n",
    "info2_agg = pl.from_pandas(agg_df.reset_index())\n",
    "\n",
    "\n",
    "train = pl.read_csv(TRAIN_FILE).drop(\"\")\n",
    "test  = pl.read_csv(TEST_FILE).drop(\"\")\n",
    "\n",
    "def enrich(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    return (\n",
    "        df.lazy()\n",
    "          .join(info1.lazy(),    on=\"mint\", how=\"left\")\n",
    "          .join(info2_agg.lazy(), on=\"mint\", how=\"left\")\n",
    "          .fill_null(0)\n",
    "          .collect(streaming=True)\n",
    "    )\n",
    "\n",
    "train_enriched = enrich(train)\n",
    "test_enriched  = enrich(test)\n",
    "\n",
    "\n",
    "y = train_enriched[\"has_graduated\"]\n",
    "X = train_enriched.drop([\"mint\", \"has_graduated\", \"slot_graduated\"])\n",
    "\n",
    "\n",
    "float_cols = [c for c, dt in zip(X.columns, X.dtypes) if dt == pl.Float64]\n",
    "X = X.with_columns([pl.col(c).cast(pl.Float32) for c in float_cols])\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X.to_pandas(), y.to_pandas(),\n",
    "    test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "model = LGBMClassifier(\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=64,\n",
    "    n_estimators=1000,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric=\"binary_logloss\",\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=50),\n",
    "        log_evaluation(period=100)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "sample_pd = pd.read_csv(SAMPLE_SUB)\n",
    "X_test    = test_enriched.drop([\"mint\"]).to_pandas()\n",
    "preds     = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "sample_pd[\"has_graduated\"] = preds\n",
    "sample_pd.to_csv(\"submission.csv\", index=False)\n",
    "print(\"submission.csv saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11856763,
     "sourceId": 97569,
     "sourceType": "competition"
    },
    {
     "datasetId": 7012766,
     "sourceId": 11407081,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7142049,
     "sourceId": 11447533,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 134.479306,
   "end_time": "2025-04-26T18:35:51.493963",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-26T18:33:37.014657",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
